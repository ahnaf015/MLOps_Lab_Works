{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Experiment - Wine Quality Classification\n",
    "This notebook demonstrates MLflow tracking with a different dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import mlflow\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from joblib import dump\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Cache Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Wine dataset for the first time...\n",
      "Dataset cached successfully!\n",
      "Dataset shape: (178, 13)\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Check if the pickle files exist (using different names to avoid conflicts)\n",
    "data_dir = './data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "wine_data_path = os.path.join(data_dir, 'wine_data.pickle')\n",
    "wine_target_path = os.path.join(data_dir, 'wine_target.pickle')\n",
    "\n",
    "if os.path.exists(wine_data_path) and os.path.exists(wine_target_path): \n",
    "    print(\"Loading cached Wine dataset...\")\n",
    "    X = pickle.load(open(wine_data_path, 'rb'))\n",
    "    y = pickle.load(open(wine_target_path, 'rb'))\n",
    "else:\n",
    "    print(\"Fetching Wine dataset for the first time...\")\n",
    "    wine = load_wine()\n",
    "    X = wine.data\n",
    "    y = wine.target\n",
    "    \n",
    "    pickle.dump(X, open(wine_data_path, 'wb'))\n",
    "    pickle.dump(y, open(wine_target_path, 'wb'))\n",
    "    print(\"Dataset cached successfully!\")\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(set(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Experiment Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created experiment: Wine Quality Dataset_260129_215936\n",
      "Experiment ID: 808277251728951572\n",
      "MLflow tracking URI: ./mlruns\n",
      "Saving to: c:\\Users\\tajwa\\Desktop\\MLOPS\\MLOps_lab_works\\Github_Labs\\Lab2\\src\\mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tajwa\\anaconda3\\envs\\ml6-gpu\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow tracking URI (same location as train_model.py)\n",
    "mlruns_dir = './mlruns'\n",
    "os.makedirs(mlruns_dir, exist_ok=True)\n",
    "mlflow.set_tracking_uri(mlruns_dir)\n",
    "\n",
    "# Experiment details\n",
    "dataset_name = \"Wine Quality Dataset\"\n",
    "current_time = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "experiment_name = f\"{dataset_name}_{current_time}\"    \n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "print(f\"Created experiment: {experiment_name}\")\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Saving to: {os.path.abspath(mlruns_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 124\n",
      "Test set size: 54\n",
      "\n",
      "Training Gradient Boosting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 21:59:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.9630\n",
      "F1 Score (Macro): 0.9652\n",
      "F1 Score (Weighted): 0.9627\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        18\n",
      "           1       0.91      1.00      0.95        21\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.97      0.96      0.97        54\n",
      "weighted avg       0.97      0.96      0.96        54\n",
      "\n",
      "\n",
      "Model saved to: c:\\Users\\tajwa\\Desktop\\MLOPS\\MLOps_lab_works\\Github_Labs\\Lab2\\models\\model_260129_215936_gb_model.joblib\n",
      "Scaler saved to: c:\\Users\\tajwa\\Desktop\\MLOPS\\MLOps_lab_works\\Github_Labs\\Lab2\\models\\scaler_260129_215936.joblib\n",
      "\n",
      "✅ Experiment logged successfully to MLflow!\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id, run_name=dataset_name):\n",
    "    \n",
    "    # Log dataset parameters\n",
    "    params = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"number_of_datapoints\": X.shape[0],\n",
    "        \"number_of_features\": X.shape[1],\n",
    "        \"number_of_classes\": len(set(y)),\n",
    "        \"model_type\": \"GradientBoostingClassifier\"\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train Gradient Boosting Classifier\n",
    "    gb_clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining Gradient Boosting Classifier...\")\n",
    "    gb_clf.fit(X_train_scaled, y_train)\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # Model hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"n_estimators\": 100,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 3\n",
    "    })\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = gb_clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate and log metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'Accuracy': accuracy,\n",
    "        'F1_Score_Macro': f1_macro,\n",
    "        'F1_Score_Weighted': f1_weighted\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nModel Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save model (matching train_model.py structure: Lab2/models)\n",
    "    models_dir = os.path.join('..', 'models')\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    model_filename = os.path.join(models_dir, f'model_{current_time}_gb_model.joblib')\n",
    "    dump(gb_clf, model_filename)\n",
    "    print(f\"\\nModel saved to: {os.path.abspath(model_filename)}\")\n",
    "    \n",
    "    # Save scaler as well\n",
    "    scaler_filename = os.path.join(models_dir, f'scaler_{current_time}.joblib')\n",
    "    dump(scaler, scaler_filename)\n",
    "    print(f\"Scaler saved to: {os.path.abspath(scaler_filename)}\")\n",
    "    \n",
    "    # Log model to MLflow\n",
    "    mlflow.sklearn.log_model(gb_clf, \"gradient_boosting_model\")\n",
    "    \n",
    "    print(\"\\n✅ Experiment logged successfully to MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View MLflow UI\n",
    "Since this notebook now saves to `./mlruns` (same as train_model.py), run:\n",
    "```bash\n",
    "# From the src/ directory:\n",
    "python -m mlflow ui --backend-store-uri ./mlruns\n",
    "\n",
    "# Or from Lab2/ directory:\n",
    "python -m mlflow ui --backend-store-uri ./src/mlruns\n",
    "```\n",
    "Then navigate to http://localhost:5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml6-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
